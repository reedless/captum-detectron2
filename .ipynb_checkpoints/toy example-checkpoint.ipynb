{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bc63343",
   "metadata": {},
   "source": [
    "## Captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "300ad6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from captum.attr import (\n",
    "    GradientShap,\n",
    "    DeepLift,\n",
    "    DeepLiftShap,\n",
    "    IntegratedGradients,\n",
    "    LayerConductance,\n",
    "    NeuronConductance,\n",
    "    NoiseTunnel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d8e1998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(3, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(3, 2)\n",
    "\n",
    "        # initialize weights and biases\n",
    "        self.lin1.weight = nn.Parameter(torch.arange(-4.0, 5.0).view(3, 3))\n",
    "        self.lin1.bias = nn.Parameter(torch.zeros(1,3))\n",
    "        self.lin2.weight = nn.Parameter(torch.arange(-3.0, 3.0).view(2, 3))\n",
    "        self.lin2.bias = nn.Parameter(torch.ones(1,2))\n",
    "\n",
    "    def forward(self, input):\n",
    "        print(input.shape)\n",
    "        return self.lin2(self.relu(self.lin1(input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea89d49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToyModel(\n",
       "  (lin1): Linear(in_features=3, out_features=3, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (lin2): Linear(in_features=3, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ToyModel()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0979828",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_input = torch.rand(2, 3)\n",
    "baseline = torch.zeros((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21e90a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "IG Attributions: tensor([[-1.8479, -0.3526, -1.5562],\n",
      "        [ 0.0000, -2.2000, -4.2150]], dtype=torch.float64)\n",
      "Convergence Delta: tensor([5.9605e-08, 1.1921e-07], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "ig = IntegratedGradients(model)\n",
    "attributions, delta = ig.attribute(toy_input, baseline, target=0, return_convergence_delta=True)\n",
    "print('IG Attributions:', attributions)\n",
    "print('Convergence Delta:', delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d0c93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68abc710",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GradientShap(model)\n",
    "\n",
    "# We define a distribution of baselines and draw `n_samples` from that\n",
    "# distribution in order to estimate the expectations of gradients across all baselines\n",
    "baseline_dist = torch.randn(5, 3, 480, 640) * 0.001\n",
    "attributions, delta = gs.attribute(input_, stdevs=0.09, n_samples=4, baselines=baseline_dist,\n",
    "                                   target=0, return_convergence_delta=True)\n",
    "print('GradientShap Attributions:', attributions)\n",
    "print('Convergence Delta:', delta)\n",
    "print('Average delta per example:', torch.mean(delta.reshape(input.shape[0], -1), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab3eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DeepLift(model)\n",
    "attributions, delta = dl.attribute(input_, baseline, target=0, return_convergence_delta=True)\n",
    "print('DeepLift Attributions:', attributions)\n",
    "print('Convergence Delta:', delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861aadd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl = DeepLiftShap(model)\n",
    "attributions, delta = dl.attribute(input_.float(), baseline_dist, target=0, return_convergence_delta=True)\n",
    "print('DeepLiftSHAP Attributions:', attributions)\n",
    "print('Convergence Delta:', delta)\n",
    "print('Average delta per example:', torch.mean(delta.reshape(input.shape[0], -1), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1f5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(model)\n",
    "nt = NoiseTunnel(ig)\n",
    "attributions, delta = nt.attribute(input_, nt_type='smoothgrad', stdevs=0.02, nt_samples=4,\n",
    "      baselines=baseline, target=0, return_convergence_delta=True)\n",
    "print('IG + SmoothGrad Attributions:', attributions)\n",
    "print('Convergence Delta:', delta)\n",
    "print('Average delta per example', torch.mean(delta.reshape(input.shape[0], -1), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da398095",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = NeuronConductance(model, model.backbone)\n",
    "attributions = nc.attribute(input_, neuron_selector=1, target=0)\n",
    "print('Neuron Attributions:', attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b5ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = LayerConductance(model, model.backbone)\n",
    "attributions, delta = lc.attribute(input_, baselines=baseline, target=0, return_convergence_delta=True)\n",
    "print('Layer Attributions:', attributions)\n",
    "print('Convergence Delta:', delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796591ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a23634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f178d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4804a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d6242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937c7d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf326394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "captum-vas",
   "language": "python",
   "name": "captum-vas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
